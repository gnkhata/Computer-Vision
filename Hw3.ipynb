{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import numpy as np \n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "from scipy.signal import convolve2d\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import pandas as pd\n",
    "\n",
    "from Utilities import *\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading MNIST dataset and  Zero-padding & Normalization to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading mnist dataset\n",
    "(train_image, train_label), (test_image, test_label) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images is: (60000, 28, 28)\n",
      "Shape of testing images is:  (10000, 28, 28)\n",
      "Shape of a single image is:  (28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training images is:\", train_image.shape)\n",
    "print(\"Shape of testing images is: \", test_image.shape)\n",
    "\n",
    "print(\"Shape of a single image is: \", train_image[0].shape)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of training image with padding: (60000, 32, 32, 1)\n",
      "The shape of testing image with padding:  (10000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "#Zero-padding & Normalization to the training data\n",
    "train_image_normalized_pad = normalize(zero_pad(train_image[:,:,:,np.newaxis], 2),'LeNet')\n",
    "test_image_normalized_pad  = normalize(zero_pad(test_image[:,:,:,np.newaxis],  2),'LeNet')\n",
    "print(\"The shape of training image with padding:\", train_image_normalized_pad.shape)\n",
    "print(\"The shape of testing image with padding: \", test_image_normalized_pad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 2.1 Inner Product Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function implemented within a class  \n",
    "class FCLayer(object):\n",
    "    def __init__(self, weight_shape, init_mode='Gaussian_dist'): \n",
    "        \n",
    "        # Initialization\n",
    "        self.v_w, self.v_b = np.zeros(weight_shape), np.zeros((weight_shape[-1],))\n",
    "        self.weight, self.bias = initialize(weight_shape, init_mode)\n",
    "    \n",
    "    #Q 2.1 Inner Product Layer   \n",
    "    def foward_prop(self, input_array):\n",
    "        self.input_array = input_array  #(n_m, 120)\n",
    "        return np.matmul(self.input_array, self.weight) # (n_m, 84)\n",
    "    \n",
    "    #Q 3.2 Inner Product layer   \n",
    "    def back_prop(self, dZ, momentum, weight_decay):\n",
    "        dA = np.matmul(dZ, self.weight.T)               # (n_m, 84) * (84, 120) = (n_m, 120)\n",
    "        dW = np.matmul(self.input_array.T, dZ)          # (n_m, 120).T * (n_m, 84) = (120, 84)\n",
    "        db = np.sum(dZ.T, axis=1)                       # (84,)\n",
    "        \n",
    "        self.weight, self.bias, self.v_w, self.v_b = \\\n",
    "            update(self.weight, self.bias, dW, db, self.v_w, self.v_b, self.lr, momentum, weight_decay)\n",
    "        return dA\n",
    "    \n",
    "    # Stochastic Diagonal Levenberg-Marquaedt\n",
    "    def SDLM(self, d2Z, mu, lr_global):\n",
    "        d2A = np.matmul(d2Z, np.power(self.weight.T,2))\n",
    "        d2W = np.matmul(np.power(self.input_array.T,2), d2Z)\n",
    "        h = np.sum(d2W)/d2Z.shape[0]\n",
    "        self.lr = lr_global / (mu + h)\n",
    "        return d2A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 2.2 Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling_layer_forward(A_prev, hparameters, mode):\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    \n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "\n",
    "    A = np.zeros((m, n_H, n_W, n_C))      \n",
    "    for h in range(n_H):                      # loop on the vertical axis of the output volume\n",
    "        for w in range(n_W):                  # loop on the horizontal axis of the output volume\n",
    "            # Use the corners to define the current slice on the ith training example of A_prev, channel c\n",
    "            A_prev_slice = A_prev[:, h*stride:h*stride+f, w*stride:w*stride+f, :]  \n",
    "            # Compute the pooling operation on the slice. Use an if statment to differentiate the modes. \n",
    "            if mode == \"max\":\n",
    "                A[:, h, w, :] = np.max(A_prev_slice, axis=(1,2))\n",
    "            elif mode == \"average\":\n",
    "                A[:, h, w, :] = np.average(A_prev_slice, axis=(1,2))\n",
    "\n",
    "    cache = (A_prev, hparameters)\n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    return A, cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 2.3 Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer_forward(A_prev, W, b, hparameters):\n",
    "    \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    n_H = int((n_H_prev + 2*pad - f)/stride + 1)\n",
    "    n_W = int((n_W_prev + 2*pad - f)/stride + 1)\n",
    "    \n",
    "    # Initialize the output volume Z with zeros. \n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    for h in range(n_H):                            # loop over vertical axis of the output volume\n",
    "        for w in range(n_W):                        # loop over horizontal axis of the output volume\n",
    "            A_slice_prev = A_prev_pad[:, h*stride:h*stride+f, w*stride:w*stride+f, :]\n",
    "            Z[:, h, w, :] = np.tensordot(A_slice_prev, W, axes=([1,2,3],[0,1,2])) + b\n",
    "                            \n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 2.4 ReLU forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReLU activation\n",
    "def relu_forward(inputs):\n",
    "    return np.where(inputs>0, inputs, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.1 ReLU backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(inputs):\n",
    "    return np.where(inputs>0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.2 Inner Product layer backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Code for this is implemented above under Q 2.1 Inner Product Layer in FCLayer class'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Code for this is implemented above under Q 2.1 Inner Product Layer in FCLayer class\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions for ReLU layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper activation functions\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "def d_tanh(x):\n",
    "    return 1/np.power(np.cosh(x),2)\n",
    "\n",
    "def LeNet_squash(x):\n",
    "    return 1.7159*np.tanh(2*x/3)\n",
    "def d_LeNet_squash(x):\n",
    "    return 1.14393*(1-np.power(tanh(2*x/3),2))\n",
    "\n",
    "def activation_func():\n",
    "    actf = [LeNet_squash, tanh, relu_forward]\n",
    "    actfName = [act.__name__ for act in actf]\n",
    "    d_actf = [d_LeNet_squash, d_tanh, relu_backward]\n",
    "    d_actfName = [d_act.__name__ for d_act in d_actf]\n",
    "    return (actf, d_actf), actfName\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper classes to LeNet Layers above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(object):\n",
    "    def __init__(self, kernel_shape, hparameters, init_mode='Gaussian_dist'):\n",
    "        self.hparameters = hparameters\n",
    "        self.weight, self.bias = initialize(kernel_shape, init_mode)\n",
    "        self.v_w, self.v_b = np.zeros(kernel_shape), np.zeros((1,1,1,kernel_shape[-1]))\n",
    "        \n",
    "    def foward_prop(self, input_map):\n",
    "        output_map, self.cache = conv_layer_forward(input_map, self.weight, self.bias, self.hparameters)\n",
    "        return output_map\n",
    "    \n",
    "    def back_prop(self, dZ, momentum, weight_decay):\n",
    "        dA_prev, dW, db = conv_backward(dZ, self.cache)\n",
    "        self.weight, self.bias, self.v_w, self.v_b = \\\n",
    "            update(self.weight, self.bias, dW, db, self.v_w, self.v_b, self.lr, momentum, weight_decay)\n",
    "        return dA_prev  \n",
    "    \n",
    "    def SDLM(self, d2Z, mu, lr_global):\n",
    "        d2A_prev, d2W = conv_SDLM(d2Z, self.cache)\n",
    "        h = np.sum(d2W)/d2Z.shape[0]\n",
    "        self.lr = lr_global / (mu + h)\n",
    "        return d2A_prev \n",
    "    \n",
    "# Conv3: Convlayer with assigned combination between input maps and weight\n",
    "class ConvLayer_maps(object):\n",
    "    def __init__(self, kernel_shape, hparameters, mapping, init_mode='Gaussian_dist'):\n",
    "        self.hparameters = hparameters\n",
    "        self.mapping     = mapping\n",
    "        self.wb   = []      # list of [weight, bias]\n",
    "        self.v_wb = []      # list of [v_w,    v_b]\n",
    "        for i in range(len(self.mapping)):\n",
    "            weight_shape = (kernel_shape[0], kernel_shape[1], len(self.mapping[i]), 1)\n",
    "            w, b = initialize(weight_shape, init_mode)\n",
    "            self.wb.append([w, b])\n",
    "            self.v_wb.append([np.zeros(w.shape), np.zeros(b.shape)])\n",
    "        \n",
    "    def foward_prop(self, input_map):\n",
    "        self.iputmap_shape = input_map.shape #(n_m,14,14,6)\n",
    "        self.caches = []\n",
    "        output_maps = []\n",
    "        for i in range(len(self.mapping)):\n",
    "            output_map, cache = conv_layer_forward(input_map[:,:,:,self.mapping[i]], self.wb[i][0], self.wb[i][1], self.hparameters)\n",
    "            output_maps.append(output_map)\n",
    "            self.caches.append(cache)\n",
    "        output_maps = np.swapaxes(np.array(output_maps),0,4)[0]\n",
    "        return output_maps\n",
    "    \n",
    "    def back_prop(self, dZ, momentum, weight_decay):\n",
    "        dA_prevs = np.zeros(self.iputmap_shape)\n",
    "        for i in range(len(self.mapping)):\n",
    "            dA_prev, dW, db = conv_backward(dZ[:,:,:,i:i+1], self.caches[i])\n",
    "            self.wb[i][0], self.wb[i][1], self.v_wb[i][0], self.v_wb[i][1] =\\\n",
    "                update(self.wb[i][0], self.wb[i][1], dW, db, self.v_wb[i][0], self.v_wb[i][1], self.lr, momentum, weight_decay)\n",
    "            dA_prevs[:,:,:,self.mapping[i]] += dA_prev\n",
    "        return dA_prevs \n",
    "    \n",
    "    # Stochastic Diagonal Levenberg-Marquaedt\n",
    "    def SDLM(self, d2Z, mu, lr_global):\n",
    "        h = 0\n",
    "        d2A_prevs = np.zeros(self.iputmap_shape)\n",
    "        for i in range(len(self.mapping)):\n",
    "            d2A_prev, d2W = conv_SDLM(d2Z[:,:,:,i:i+1], self.caches[i])\n",
    "            d2A_prevs[:,:,:,self.mapping[i]] += d2A_prev\n",
    "            h += np.sum(d2W)\n",
    "        self.lr = lr_global / (mu + h/d2Z.shape[0])\n",
    "        return d2A_prevs\n",
    "\n",
    "class PoolingLayer(object):\n",
    "    def __init__(self, hparameters, mode):\n",
    "        self.hparameters = hparameters\n",
    "        self.mode = mode\n",
    "        \n",
    "    def foward_prop(self, input_map):   # n,28,28,6 / n,10,10,16\n",
    "        A, self.cache = pooling_layer_forward(input_map, self.hparameters, self.mode)\n",
    "        return A\n",
    "    \n",
    "    def back_prop(self, dA):\n",
    "        dA_prev = pool_backward(dA, self.cache, self.mode)\n",
    "        return dA_prev\n",
    "    \n",
    "    def SDLM(self, d2A):\n",
    "        d2A_prev = pool_backward(d2A, self.cache, self.mode)\n",
    "        return d2A_prev\n",
    "\n",
    "class Activation(object):\n",
    "    def __init__(self, mode):    \n",
    "        (act, d_act), actfName = activation_func()\n",
    "        act_index  = actfName.index(mode)\n",
    "        self.act   = act[act_index]\n",
    "        self.d_act = d_act[act_index]\n",
    "        \n",
    "    def foward_prop(self, input_image): \n",
    "        self.input_image = input_image\n",
    "        return self.act(input_image)\n",
    "    \n",
    "    def back_prop(self, dZ):\n",
    "        dA = np.multiply(dZ, self.d_act(self.input_image)) \n",
    "        return dA\n",
    "    \n",
    "    # Stochastic Diagonal Levenberg-Marquaedt\n",
    "    def SDLM(self, d2Z):  #d2_LeNet_squash\n",
    "        dA = np.multiply(d2Z, np.power(self.d_act(self.input_image),2)) \n",
    "        return dA\n",
    "\n",
    "# not even slightly work\n",
    "class RBFLayer_trainable_weight(object):\n",
    "    def __init__(self, weight_shape, init_weight=None, init_mode='Gaussian_dist'): \n",
    "        self.weight_shape = weight_shape # =(10, 84)\n",
    "        self.v_w = np.zeros(weight_shape)\n",
    "\n",
    "        if init_weight.shape == (10,84):\n",
    "            self.weight = init_weight\n",
    "        else:\n",
    "            self.weight, _ = initialize(weight_shape, init_mode)\n",
    "        \n",
    "    def foward_prop(self, input_array, label, mode): \n",
    "        \n",
    "        if mode == 'train':\n",
    "            self.input_array = input_array\n",
    "            self.weight_label = self.weight[label,:]  #(n_m, 84) labeled version of weight\n",
    "            loss = 0.5 * np.sum(np.power(input_array - self.weight_label, 2), axis=1, keepdims=True)  #(n_m, )\n",
    "            return np.sum(np.squeeze(loss))\n",
    "        \n",
    "        if mode == 'test':\n",
    "            subtract_weight = (input_array[:,np.newaxis,:] - np.array([self.weight]*input_array.shape[0])) # (n_m,10,84)\n",
    "            rbf_class = np.sum(np.power(subtract_weight,2), axis=2) # (n_m, 10)\n",
    "            class_pred = np.argmin(rbf_class, axis=1) # (n_m,)\n",
    "            error01 = np.sum(label != class_pred)\n",
    "            return error01, class_pred\n",
    "\n",
    "    def back_prop(self, label, lr, momentum, weight_decay):\n",
    "        \n",
    "        dy_predict = -self.weight_label + self.input_array    #(n_m, 84)\n",
    "        \n",
    "        dW_target  = -dy_predict                              #(n_m, 84)\n",
    "        \n",
    "        dW = np.zeros(self.weight_shape) # (10,84)\n",
    "        \n",
    "        for i in range(len(label)):  \n",
    "            dW[label[i],:] += dW_target[i,:]\n",
    "            \n",
    "        self.v_w = momentum*self.v_w - weight_decay*lr*self.weight - lr*dW\n",
    "        self.weight += self.v_w\n",
    "\n",
    "        return dy_predict\n",
    "\n",
    "bitmap = rbf_init_weight()\n",
    "\n",
    "class RBFLayer(object):\n",
    "    def __init__(self, weight):        \n",
    "        self.weight = weight  # (10, 84)\n",
    "        \n",
    "    def foward_prop(self, input_array, label, mode): \n",
    "        if mode == 'train':\n",
    "            self.input_array = input_array\n",
    "            self.weight_label = self.weight[label,:]  #(n_m, 84) labeled version of weight\n",
    "            loss = 0.5 * np.sum(np.power(input_array - self.weight_label, 2), axis=1, keepdims=True)  #(n_m, )\n",
    "            return np.sum(np.squeeze(loss))\n",
    "        if mode == 'test':\n",
    "            # (n_m,1,84) - n_m*[(10,84)] = (n_m,10,84)\n",
    "            subtract_weight = (input_array[:,np.newaxis,:] - np.array([self.weight]*input_array.shape[0])) # (n_m,10,84)\n",
    "            rbf_class = np.sum(np.power(subtract_weight,2), axis=2) # (n_m, 10)\n",
    "            class_pred = np.argmin(rbf_class, axis=1) # (n_m,)\n",
    "            error01 = np.sum(label != class_pred)\n",
    "            return error01, class_pred\n",
    "        \n",
    "    def back_prop(self):\n",
    "        dy_predict = -self.weight_label + self.input_array    #(n_m, 84)\n",
    "        return dy_predict\n",
    "    \n",
    "    def SDLM(self):\n",
    "        # d2y_predict\n",
    "        return np.ones(self.input_array.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate combination of kernels and feature maps of MaxP2.\n",
    "Conv3_mapping = [[0,1,2],[1,2,3],[2,3,4],[3,4,5],[4,5,0],[5,0,1],\\\n",
    "              [0,1,2,3],[1,2,3,4],[2,3,4,5],[3,4,5,0],[4,5,0,1],[5,0,1,2],\\\n",
    "              [0,1,3,4],[1,2,4,5],[0,2,3,5],\\\n",
    "              [0,1,2,3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The fixed weight (7x12 preset ASCII bitmaps) used in the RBF layer.\n",
    "bitmap = rbf_init_weight()\n",
    "fig, axarr = plt.subplots(2,5,figsize=(20,8))\n",
    "for i in range(10):\n",
    "    x,y = int(i/5), i%5\n",
    "    axarr[x,y].set_title(str(i))\n",
    "    axarr[x,y].imshow(bitmap[i,:].reshape(12,7), cmap=mpl.cm.Greys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class that puts everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# LeNet object (also stored in utils/LayerObjects.py)\n",
    "class LeNet(object):\n",
    "    def __init__(self):\n",
    "        kernel_shape = {\"Conv1\": (5,5,1,6),\n",
    "                        \"Conv3\": (5,5,6,16),    ### Conv3 has designated combinations\n",
    "                        \"Conv5\": (5,5,16,120),  ### It's actually a FC layer\n",
    "                        \"FCL6\": (120,84),\n",
    "                        \"OUTPUT\": (84,10)}\n",
    "        \n",
    "        hparameters_convlayer = {\"stride\": 1, \"pad\": 0}\n",
    "        hparameters_pooling   = {\"stride\": 2, \"f\": 2}        \n",
    "        \n",
    "        self.Conv1 = ConvLayer(kernel_shape[\"Conv1\"], hparameters_convlayer)\n",
    "        self.a1 = Activation(\"LeNet_squash\")\n",
    "        self.MaxP2 = PoolingLayer(hparameters_pooling, \"average\")\n",
    "        \n",
    "        self.Conv3 = ConvLayer_maps(kernel_shape[\"Conv3\"], hparameters_convlayer, Conv3_mapping)\n",
    "        self.a2 = Activation(\"LeNet_squash\")\n",
    "        self.MaxP4 = PoolingLayer(hparameters_pooling, \"average\")\n",
    "        \n",
    "        self.Conv5 = ConvLayer(kernel_shape[\"Conv5\"], hparameters_convlayer)\n",
    "        self.a3 = Activation(\"LeNet_squash\")\n",
    "\n",
    "        self.FCL6 = FCLayer(kernel_shape[\"FCL6\"])\n",
    "        self.a4 = Activation(\"LeNet_squash\")\n",
    "        \n",
    "        self.Output = RBFLayer(bitmap)\n",
    "        \n",
    "    def Forward_Propagation(self, input_image, input_label, mode): \n",
    "        self.label = input_label\n",
    "        self.Conv1_FP = self.Conv1.foward_prop(input_image)\n",
    "        self.a1_FP = self.a1.foward_prop(self.Conv1_FP)\n",
    "        self.MaxP2_FP = self.MaxP2.foward_prop(self.a1_FP)\n",
    "\n",
    "        self.Conv3_FP = self.Conv3.foward_prop(self.MaxP2_FP)\n",
    "        self.a2_FP = self.a2.foward_prop(self.Conv3_FP)\n",
    "        self.MaxP4_FP = self.MaxP4.foward_prop(self.a2_FP)\n",
    "\n",
    "        self.Conv5_FP = self.Conv5.foward_prop(self.MaxP4_FP)\n",
    "        self.a3_FP = self.a3.foward_prop(self.Conv5_FP)\n",
    "\n",
    "        self.flatten = self.a3_FP[:,0,0,:]\n",
    "        self.FCL6_FP = self.FCL6.foward_prop(self.flatten)\n",
    "        self.a4_FP = self.a4.foward_prop(self.FCL6_FP)  \n",
    "        \n",
    "        # output sum of the loss over mini-batch when mode = 'train'\n",
    "        # output tuple of (0/1 error, class_predict) when mode = 'test'\n",
    "        out  = self.Output.foward_prop(self.a4_FP, input_label, mode) \n",
    "\n",
    "        return out \n",
    "        \n",
    "    def Back_Propagation(self, momentum, weight_decay):\n",
    "        dy_pred = self.Output.back_prop()\n",
    "        \n",
    "        dy_pred = self.a4.back_prop(dy_pred)\n",
    "        FCL6_BP = self.FCL6.back_prop(dy_pred, momentum, weight_decay)\n",
    "        reverse_flatten = FCL6_BP[:,np.newaxis,np.newaxis,:]\n",
    "        \n",
    "        reverse_flatten = self.a3.back_prop(reverse_flatten) \n",
    "        Conv5_BP = self.Conv5.back_prop(reverse_flatten, momentum, weight_decay)\n",
    "        \n",
    "        MaxP4_BP = self.MaxP4.back_prop(Conv5_BP)\n",
    "        MaxP4_BP = self.a2.back_prop(MaxP4_BP)\n",
    "        Conv3_BP = self.Conv3.back_prop(MaxP4_BP, momentum, weight_decay) \n",
    "        \n",
    "        MaxP2_BP = self.MaxP2.back_prop(Conv3_BP)\n",
    "        MaxP2_BP = self.a1.back_prop(MaxP2_BP)  \n",
    "        Conv1_BP = self.Conv1.back_prop(MaxP2_BP, momentum, weight_decay)\n",
    "        \n",
    "    # Stochastic Diagonal Levenberg-Marquaedt method for determining the learning rate before the beginning of each epoch\n",
    "    def SDLM(self, mu, lr_global):\n",
    "        d2y_pred = self.Output.SDLM()\n",
    "        d2y_pred = self.a4.SDLM(d2y_pred)\n",
    "        \n",
    "        FCL6_SDLM = self.FCL6.SDLM(d2y_pred, mu, lr_global)\n",
    "        reverse_flatten = FCL6_SDLM[:,np.newaxis,np.newaxis,:]\n",
    "        \n",
    "        reverse_flatten = self.a3.SDLM(reverse_flatten) \n",
    "        Conv5_SDLM = self.Conv5.SDLM(reverse_flatten, mu, lr_global)\n",
    "        \n",
    "        MaxP4_SDLM = self.MaxP4.SDLM(Conv5_SDLM)\n",
    "        MaxP4_SDLM = self.a2.SDLM(MaxP4_SDLM)\n",
    "        Conv3_SDLM = self.Conv3.SDLM(MaxP4_SDLM, mu, lr_global)\n",
    "        \n",
    "        MaxP2_SDLM = self.MaxP2.SDLM(Conv3_SDLM)\n",
    "        MaxP2_SDLM = self.a1.SDLM(MaxP2_SDLM)  \n",
    "        Conv1_SDLM = self.Conv1.SDLM(MaxP2_SDLM, mu, lr_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvNet = LeNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epoches & learning rate in the original paper\n",
    "epoch_orig, lr_global_orig = 20, np.array([5e-4]*2 + [2e-4]*3 + [1e-4]*3 + [5e-5]*4 + [1e-5]*8) \n",
    "\n",
    "# Number of epoches & learning rate I used\n",
    "epoches, lr_global_list = epoch_orig, lr_global_orig*100\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 0\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- epoch 1 begin ----------\n",
      "global learning rate: 0.05\n",
      "learning rates in trainable layers: [1.89168415e-05 1.15641276e-05 1.95795304e-05 1.98585574e-05]\n",
      "batch size: 256\n",
      "Momentum: 0.9 , weight decay: 0\n",
      "\u001b[F\u001b[Kprogress: 4 %,  cost = 110105.90033475994\r"
     ]
    }
   ],
   "source": [
    "#Training loops\n",
    "st = time.time()\n",
    "cost_last, count = np.Inf, 0\n",
    "err_rate_list = []\n",
    "for epoch in range(0,epoches):\n",
    "    print(\"---------- epoch\", epoch+1, \"begin ----------\")\n",
    "    \n",
    "    # Stochastic Diagonal Levenberg-Marquaedt method for determining the learning rate \n",
    "    (batch_image, batch_label) = random_mini_batches(train_image_normalized_pad, train_label, mini_batch_size = 500, one_batch=True)\n",
    "    ConvNet.Forward_Propagation(batch_image, batch_label, 'train')\n",
    "    lr_global = lr_global_list[epoch]\n",
    "    ConvNet.SDLM(0.02, lr_global)\n",
    "    \n",
    "    # print info\n",
    "    print(\"global learning rate:\", lr_global)\n",
    "    print(\"learning rates in trainable layers:\", np.array([ConvNet.Conv1.lr, ConvNet.Conv3.lr, ConvNet.Conv5.lr, ConvNet.FCL6.lr]))\n",
    "    print(\"batch size:\", batch_size)\n",
    "    print(\"Momentum:\",momentum,\", weight decay:\",weight_decay)\n",
    "    \n",
    "    #loop over each batch\n",
    "    ste = time.time()\n",
    "    cost = 0\n",
    "    mini_batches = random_mini_batches(train_image_normalized_pad, train_label, batch_size)\n",
    "    for i in range(len(mini_batches)):\n",
    "        batch_image, batch_label = mini_batches[i]\n",
    "        \n",
    "        loss = ConvNet.Forward_Propagation(batch_image, batch_label, 'train')     \n",
    "        cost += loss\n",
    "        \n",
    "        ConvNet.Back_Propagation(momentum, weight_decay) \n",
    "\n",
    "        # print progress\n",
    "        if i%(int(len(mini_batches)/100))==0:\n",
    "            sys.stdout.write(\"\\033[F\")   #CURSOR_UP_ONE\n",
    "            sys.stdout.write(\"\\033[K\")   #ERASE_LINE\n",
    "            print (\"progress:\", int(100*(i+1)/len(mini_batches)), \"%, \", \"cost =\", cost, end='\\r')\n",
    "    sys.stdout.write(\"\\033[F\")   #CURSOR_UP_ONE\n",
    "    sys.stdout.write(\"\\033[K\")   #ERASE_LINE\n",
    "    \n",
    "    print (\"Done, cost of epoch\", epoch+1, \":\", cost,\"                                             \")\n",
    "    \n",
    "    error01_train, _ = ConvNet.Forward_Propagation(train_image_normalized_pad, train_label, 'test')  \n",
    "    error01_test, _  = ConvNet.Forward_Propagation(test_image_normalized_pad,  test_label,  'test')     \n",
    "    err_rate_list.append([error01_train/60000, error01_test/10000])\n",
    "    print(\"0/1 error of training set:\",  error01_train, \"/\", len(train_label))\n",
    "    print(\"0/1 error of testing set: \",  error01_test,  \"/\", len(test_label))\n",
    "    print(\"Time used: \",time.time() - ste, \"sec\")\n",
    "    print(\"---------- epoch\", epoch+1, \"end ------------\")\n",
    "    with open('model_data_'+str(epoch)+'.pkl', 'wb') as output:\n",
    "        pickle.dump(ConvNet, output, pickle.HIGHEST_PROTOCOL)\n",
    "    %notebook -e output.ipynb\n",
    "    \n",
    "err_rate_list = np.array(err_rate_list).T\n",
    "print(\"Total time used: \", time.time() - st, \"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Q 4.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# read model\n",
    "with open('model_data_13.pkl', 'rb') as input_:\n",
    "    ConvNet = pickle.load(input_)\n",
    "    \n",
    "print(\"Correct label:\",test_label)\n",
    "_, pred = ConvNet.Forward_Propagation(test_image_normalized_pad, test_label, 'test')\n",
    "print(\"Predict label:\",pred)\n",
    "\n",
    "y_pred = pred\n",
    "y_test = test_label\n",
    "\n",
    "print()\n",
    "print(\"Cassification report is:\\n \",metrics.classification_report(y_test, y_pred, labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
    "\n",
    "print(\"Accuracy is: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 4.2 Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix is:\\n\", metrics.confusion_matrix(y_test, y_pred, labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.1 Output of second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MaxP2_FP = ConvNet.MaxP2_FP[0]\n",
    "print(\"Output of second layer\")\n",
    "# Feature maps of C1\n",
    "fig, axarr = plt.subplots(1,5,figsize=(18,5))\n",
    "for j in range(5):\n",
    "    axarr[j].axis('off') \n",
    "    #axarr[j].set_title( 'layer2_map'+str(j+1))\n",
    "    axarr[j].imshow(MaxP2_FP[:,:,j], cmap=mpl.cm.Greys)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Feature maps of C3\n",
    "MaxP2 = ConvNet.MaxP2_FP[0]\n",
    "\n",
    "print(\"Output of third layer\")\n",
    "\n",
    "fig, axarr = plt.subplots(4,5,figsize=(18,5))\n",
    "\n",
    "for x in range(4):\n",
    "    for y in range(5):\n",
    "    #x,y = int(j/8), j%8\n",
    "        j = x*4+y\n",
    "        axarr[x,y].axis('off') \n",
    "        #axarr[x,y].set_title( 'layer3_map'+str(j+1))\n",
    "        axarr[x,y].imshow(MaxP2[:,:,j-1], cmap=mpl.cm.Greys)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.1 Output of third layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature maps of C3\n",
    "Conv3map = ConvNet.Conv3_FP[0]\n",
    "\n",
    "print(\"Output of third layer\")\n",
    "\n",
    "fig, axarr = plt.subplots(4,5,figsize=(18,5))\n",
    "\n",
    "for x in range(4):\n",
    "    for y in range(5):\n",
    "        j = x*4+y\n",
    "        axarr[x,y].axis('off') \n",
    "        axarr[x,y].imshow(Conv3map[:,:,j-1], cmap=mpl.cm.Greys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.2 Comparing feature maps to original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fixed weight (7x12 preset ASCII bitmaps) used in the RBF layer.\n",
    "print(\"Original images are: \\n\")\n",
    "fig, axarr = plt.subplots(2,5,figsize=(20,8))\n",
    "for i in range(10):\n",
    "    x,y = int(i/5), i%5\n",
    "    axarr[x,y].set_title(str(i))\n",
    "    axarr[x,y].imshow(train_image[i, :, :], cmap=mpl.cm.Greys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra credit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 6 Image Classication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"image1.jpg\")\n",
    "print(img1.shape)\n",
    "\n",
    "img2 = cv2.imread(\"image2.jpg\")\n",
    "print(img1.shape)\n",
    "\n",
    "img3 = cv2.imread(\"image3.png\")\n",
    "print(img3.shape)\n",
    "\n",
    "img4 = cv2.imread(\"image4.jpg\")\n",
    "print(img1.shape)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
